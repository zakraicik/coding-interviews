# Management Philosophy

## Leadership Style

- **Democratic leader focused on innovation**
- Big believer that to get the most out of people, they have to buy into whatever we are working on. For that reason, I often solicit feedback from direct reports on prioritization. This is not to say we will always do what the group wants, but if there is disagreement on the team about what the right next step is - we will seek to come to consensus before moving forward.
- It is my job to set the vision and encourage innovation - oftentimes, I like to avoid setting a vision that is too lofty. Instead, I focus on chunking this lofty vision into smaller pieces that fit with an agile workflow. We work toward the larger vision over time.
- Hyperfocused on bridging data science to business objectives. Try to avoid DS/ML graveyard.

### Empowerment & Autonomy

- Believer in stretch opportunities - personally, in my experience when you throw a person into a role that they might not explicitly be qualified for, they will succeed with the right support system.
- Try to remind teams that the machine learning space is an uncertain space. To some extent, failure is okay. We can learn a lot from unsuccessful efforts.
- Encourage people to think through the cost and benefit of adopting new tools, methodologies, etc. Similar to the efficient frontier, there is no reason to take a more complex framework if the value created.
- I am accountable for the actions of my team. I focus on creating a safe space where my reports can share feedback with me privately.

## Growth Mindset

- Consistently work with ICs to develop career development plans, identify their strengths and weaknesses, and provide support where needed. This is a continuous process, not just a once a year process.
- Encourage employees to take initiative.
- Democratic input to project planning and prioritization encourages growth mindset.
- In addition to providing feedback, I will also make it known I am open to feedback as well.
- Reward employees for contribution, innovation, and effort.

# Setting Team Up for Success

## Skill Development

- Continuous career development and learning - regular career development discussions instead of annually.
- Provide a safe space for feedback - both giving and receiving.
- Provide direct line of sight to some of my responsibilities to get directs exposure to one level up.
- Provide coaching opportunities where I can.
- Mentorship opportunities.
- Shadowing opportunities.
- Leadership workshops.
- Comfortable with direct reports spending some time improving skill gaps if it can benefit the project or company.

## Team Composition

- **Strategic Planning**  
  To the extent the company is small and we don’t have large built-out teams for each function, we should consider a mix of expertise in data engineering, machine learning, statistical analysis, and business intelligence.
- Consider a mix of specialists and generalists.

### Succession Planning

- Provide clear leadership paths and promotion paths.
- Consider the team mix not only now, but in the future as well - what leadership will the team need? Is a flat org okay?
- Provide opportunities to collaborate and opportunities for collaboration.

### Encourage Innovation

- Safe space for experimentation.
- Hackathons are a fun way to give people the chance to push the boundaries on the status quo.
- Opportunities for cross-functional collaboration - machine learning is often a narrow discipline. Without spending time with other functional areas, it’s hard to deeply understand our business and focus on solving the right problems.
- Rapid prototyping and MVPs - fail fast, learn quickly.

# Project Management

## Agile Environment

- Timebox projects to prohibit analysis paralysis.
- Focus on minimum vertical slice and iterate on that - Cycles should roll up to themes which roll up to OKRs.
- Clearly defined success criteria for each.
- Emphasize flexibility and ability to pivot when needed.
- Could go either way on traditional agile ceremonies.

## Risk Management

- By default, agile cycles are designed to fail fast and learn quick - this is a risk management technique in its own way.
- As a manager, I am accountable for working with leadership and cross-functional stakeholders to understand the problems they may be facing.
- Additionally, prior to committing a cycle to a project, I invest time in feasibility research to ensure the data we have to solve the problem is comprehensive and we are impacting the correct success metrics.
- Continuous risk management -> Project risks are identified before a cycle starts, the risks are socialized (stakeholders are involved in risk management), and we know when certain risk triggers are hit to “Fail fast.”

## Stakeholder Engagement

- Regular touchpoint with relevant stakeholders.
- Manage expectations.
- Clearly communicate what we can and can’t do, and how quickly we can do it.
- Feedback loops.
- Transparent documentation.
- Cross-functional approval process.

# Conflict Negotiation

- Early identification and proactive intervention.
- Understanding root cause.
- Active listening and empathy.
- Collaborative problem-solving.
- Maintaining professionalism and respect.
- Learning from conflict.

# Communication

- Clarity and conciseness.
- Confidence when speaking.
- Active listener - respect the other person’s point of view.
- Empathetic & patient.
- Tailor presentation to the right level.
- Culturally aware.

# Experience Working with Product

- Spend time with senior leaders to get a deeper understanding of how the business operates, the challenges they face, and identify areas where machine learning can help to move the business forward.
- Feedback loop that gives stakeholders the chance to tell us what they do and don’t like about machine learning solutions currently in production.

### Understanding Product Goals and Requirements

- Active participant in roadmap creation, setting strategic product goals, and allocating resources to projects/themes quarterly.

### Strategic Influence

- Provide data-driven insights to support or reject hypotheses uncovered during the product discovery process.
- Align product objectives with data science roadmaps.
- Own feasibility analysis to inform certain areas of prioritization.
- Work with product to design and conduct experiments to measure (A/B testing).

### Response to Product

- ML-driven interventions.
- Work with engineering to design and improve data infrastructure ensuring my directs have the tools and systems they need to perform.
- Work with MLEs to streamline the deployment of production models.
  - Conversion to SageMaker endpoints.
  - Automatic training loop, etc.

### Stakeholder Education

- For our internal-facing models (underwriters), we invest a significant amount of time in making sure our end users understand the model, have a forum to voice any frustrations, and a chance to share any incorrect predictions.
- Just starting to dip our toes into helping FPA forecasting, planning, and user experience models.
- Revamping the crowbar to adapt to different types of users.

# Lessons Learned

- Communication and collaboration are king.
- Ability to present complex concepts to a non-technical audience.
- Actively listening to others' points of view ultimately helps to iterate on a solution and deploy the best possible product.
- Importance of feedback loops.
- Strategic thinking - cross-functional collaboration forces you to think outside the DS bubble and connect DS products to broader company goals/objectives.
- Prioritization skills - there are more ideas than people. Other functional areas can provide additional insights into what problems are most important to the company.
- Data talks.
- Understanding what the user really needs.
- ML is cool, but just because a model is cool doesn’t mean it will impact the success metrics driving the company.
- Defining success and quantifying impact is the easiest way to build trust in ML and impact the business.
- Remain flexible!  
  Often times, cross-functional collaboration forces you to do something differently than you might have hoped, and that’s okay.
- Different teams have different points of views, a deep understanding of company objectives can help to bridge the gap between teams.
- It’s okay to say no.

---

# Potential New Product

**Product**: Portfolio Risk Assessment and Optimization Tool for the everyday investor.

## Define the Product Vision and Objectives

- **Identify Market Needs**: Start with comprehensive research to understand the challenges and needs of DeFi investors regarding risk management.
- **Vision Statement**: Articulate a clear vision of how the product will meet these needs, focusing on the unique value proposition of using advanced data science to drive risk assessment and portfolio optimization.

### Data Science Contribution

- **Quantitative Surveys**: Conduct surveys targeting DeFi investors and portfolio managers. Use statistical analysis to quantify their concerns regarding risk management, their current methods of managing risk, and their satisfaction with existing tools.
- **Social Media and Forum Analysis**: Use natural language processing (NLP) to analyze discussions on social media platforms and forums like Reddit, Twitter, and specialized DeFi communities. Identify common themes, concerns, and gaps mentioned by the DeFi community.
- **Competitor Analysis**: Employ data scraping techniques to gather information on existing risk management tools. Analyze their features, user reviews, and popularity to identify gaps and opportunities for improvement.

## Assemble a Cross-functional Team

- **Build the Team**: Form a cross-functional team that includes data scientists, product managers, software engineers, UX/UI designers, and financial analysts with expertise in DeFi.
- **Define Roles and Responsibilities**: Ensure clear roles are established, fostering collaboration and leveraging each member's strengths.

## Conduct Feasibility Study and Data Assessment

- **Data Sources Evaluation**: Identify and evaluate the quality and availability of data sources needed for risk assessment models, including historical market data, DeFi protocols data, and regulatory information.
- **Technology Stack Assessment**: Determine the technology stack required to handle data processing, model development, and application deployment at scale.

## Prototype Development

- **Develop a Prototype**: Create an initial prototype focusing on core functionalities such as risk assessment algorithms and basic portfolio optimization features.
- **Iterative Feedback**: Test the prototype with a select group of users to gather feedback and identify areas for improvement.
- **Validation and Testing**: Validate the models against historical data and conduct stress tests to ensure accuracy and reliability under various market conditions.

## Product Design and User Experience

- **Design UX/UI**: Design a user-friendly interface that simplifies the complex analytics for end-users, ensuring that insights are accessible and actionable.
- **User Testing**: Conduct extensive user testing to refine the UX/UI, ensuring that it aligns with user expectations and needs.

## Development and Integration

- **Develop the Application**: With the validated models and final designs, develop the full application, integrating the backend with the frontend user interface.
- **Ensure user tracking in a way that is suitable for DS.**
- **Ensure Scalability and Security**: Make sure the application is scalable to handle growth and secure to protect user data and privacy.

## Launch and Market the Product

- **Product Launch Plan**: Develop a detailed launch plan that includes marketing strategies, pricing, and distribution channels.
- **Stakeholder Engagement**: Engage with stakeholders throughout the process, including potential users, to build anticipation and gather support.

## Collect Feedback and Iterate

- **Continuous Feedback Loop**: After launch, continuously collect user feedback through surveys, user analytics, and direct engagement.
- **Iterate and Improve**: Use feedback to iterate on the product, adding new features and refining existing ones to better meet user needs.

## Scale and Expand

- **Assess Market Response**: Evaluate the market response to the product, analyzing user growth, engagement, and satisfaction.
- **Scale and Expand**: Based on the initial success, scale the product to accommodate more users and explore opportunities for expanding its features or entering new markets.
